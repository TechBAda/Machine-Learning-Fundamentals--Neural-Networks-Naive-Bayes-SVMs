{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTQKcDY3uflm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# --- 1. Setup and Library Imports ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Libraries imported. Ready to run.')\n"
      ],
      "id": "bTQKcDY3uflm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-U7wASufln"
      },
      "source": [
        "## Problem 1 — Min–Max Normalization & Sigmoid NN Forward Pass  \n",
        "Prompt excerpt: Normalize inputs (AGE, INC) and compute output of a given 2-layer NN with sigmoid activations for inputs **AGE=70**, **INCOME=50K** 【112†Assignment 4.pdf†L1-L50】.\n",
        "\n",
        "**Normalization:**  \n",
        "- AGE range: 20–80 → min=20, max=80  \n",
        "- INCOME range: 10K–110K → min=10, max=110  \n",
        "\n",
        "Normalized values:\n",
        "\\[ \\text{age\\_norm} = \\frac{70-20}{80-20} = \\frac{50}{60} = 0.8333\\overline{3} \\]\n",
        "\\[ \\text{inc\\_norm} = \\frac{50-10}{110-10} = \\frac{40}{100} = 0.4 \\]\n",
        "\n",
        "The figure in the PDF contains specific **weights and biases** for each hidden and output neuron. Because those numeric weights are embedded in the diagram (not textual), we implement a **parameterized forward pass** below. **Insert the weights/biases from the figure** to evaluate the exact network output.\n"
      ],
      "id": "Hq-U7wASufln"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYwtxHiiufln"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "age, inc = 70, 50  # years, thousands\n",
        "age_min, age_max = 20, 80\n",
        "inc_min, inc_max = 10, 110\n",
        "age_norm = (age - age_min) / (age_max - age_min)\n",
        "inc_norm = (inc - inc_min) / (inc_max - inc_min)\n",
        "age_norm, inc_norm"
      ],
      "id": "VYwtxHiiufln"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eaj2xCITufln"
      },
      "outputs": [],
      "source": [
        "# --- Parameterized forward pass ---\n",
        "H = 3  # set to the number of hidden nodes shown in the figure\n",
        "\n",
        "# Replace with the exact weights from the PDF figure:\n",
        "W1 = np.array([\n",
        "    [1.0,  1.0],\n",
        "    [1.0, -1.0],\n",
        "    [-1.0, 1.0],\n",
        "], dtype=float)\n",
        "b1 = np.array([0.0, 0.0, 0.0], dtype=float)\n",
        "W2 = np.array([[1.0, 1.0, 1.0]], dtype=float)\n",
        "b2 = np.array([0.0], dtype=float)\n",
        "\n",
        "x = np.array([age_norm, inc_norm])\n",
        "h = sigmoid(W1 @ x + b1)\n",
        "y = sigmoid(W2 @ h + b2)[0]\n",
        "print({'age_norm': age_norm, 'inc_norm': inc_norm, 'hidden': h, 'output': y})\n",
        "print(\"Note: Replace placeholder weights with the actual figure values to compute the exact network output.\")\n"
      ],
      "id": "Eaj2xCITufln"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C73C-2Tufln"
      },
      "source": [
        "## Problem 2 — Boolean Networks (x1, x2, x3 ∈ {0,1}) 【112†Assignment 4.pdf†L51-L100】\n",
        "Design small neural networks (threshold/sigmoid units) that implement:\n",
        "- (a) (x1 AND x2) AND x3  \n",
        "- (b) (x1 AND x2) OR x3  \n",
        "- (c) (x1 OR x2) AND (x1 OR x3)\n",
        "\n",
        "We use **perceptron-style** units with a step activation (or steep sigmoid) to realize logic gates. For inputs in {0,1} and bias handled as a weight to a constant 1 input:\n",
        "- **AND(x,y)**: weights = [1, 1], bias = -1.5  \n",
        "- **OR(x,y)**: weights = [1, 1], bias = -0.5  \n",
        "- **NOT(x)**: weight = [-1], bias = 0.5  \n",
        "\n",
        "Implementations:\n",
        "1) **(x1 AND x2) AND x3**: two-layer ANDs: h1 = AND(x1, x2); out = AND(h1, x3).  \n",
        "2) **(x1 AND x2) OR x3**: h1 = AND(x1, x2); out = OR(h1, x3).  \n",
        "3) **(x1 OR x2) AND (x1 OR x3)**: h1 = OR(x1, x2); h2 = OR(x1, x3); out = AND(h1, h2).  \n",
        "\n",
        "Below we provide a tiny simulator to verify truth tables.\n"
      ],
      "id": "5C73C-2Tufln"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnTi0626uflo"
      },
      "outputs": [],
      "source": [
        "def step(z):\n",
        "    return (z >= 0).astype(int)\n",
        "\n",
        "def gate_AND(x, y):\n",
        "    return step(1*x + 1*y - 1.5)\n",
        "\n",
        "def gate_OR(x, y):\n",
        "    return step(1*x + 1*y - 0.5)\n",
        "\n",
        "def net_a(x1, x2, x3):\n",
        "    h1 = gate_AND(x1, x2)\n",
        "    out = gate_AND(h1, x3)\n",
        "    return out\n",
        "\n",
        "def net_b(x1, x2, x3):\n",
        "    h1 = gate_AND(x1, x2)\n",
        "    out = gate_OR(h1, x3)\n",
        "    return out\n",
        "\n",
        "def net_c(x1, x2, x3):\n",
        "    h1 = gate_OR(x1, x2)\n",
        "    h2 = gate_OR(x1, x3)\n",
        "    out = gate_AND(h1, h2)\n",
        "    return out\n",
        "\n",
        "import itertools\n",
        "rows = []\n",
        "for x1, x2, x3 in itertools.product([0,1],[0,1],[0,1]):\n",
        "    rows.append({\n",
        "        'x1': x1, 'x2': x2, 'x3': x3,\n",
        "        '(x1&x2)&x3': int(net_a(x1,x2,x3)),\n",
        "        '(x1&x2)|x3': int(net_b(x1,x2,x3)),\n",
        "        '(x1|x2)&(x1|x3)': int(net_c(x1,x2,x3)),\n",
        "    })\n",
        "pd.DataFrame(rows)"
      ],
      "id": "BnTi0626uflo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldLb3xjsuflo"
      },
      "source": [
        "## Problem 3 — Naive Bayes on Fruit (long, sweet, green) 【112†Assignment 4.pdf†L101-L150】\n",
        "Counts summary (from the prompt):\n",
        "- Priors: P(Banana)=0.5, P(Orange)=0.3, P(Other)=0.2  \n",
        "- Conditionals:\n",
        "  - Banana: long=400/500=0.8, sweet=350/500=0.7, yellow=450/500=0.9 → green means yellow=0 → P(yellow=0)=0.1  \n",
        "  - Orange: long=0/300=0.0, sweet=150/300=0.5, yellow=300/300=1.0 → P(yellow=0)=0.0  \n",
        "  - Other: long=100/200=0.5, sweet=150/200=0.75, yellow=50/200=0.25 → P(yellow=0)=0.75\n",
        "\n",
        "For features (long=1, sweet=1, yellow=0):\n",
        "- Banana score ∝ 0.5 × 0.8 × 0.7 × 0.1 = **0.028**\n",
        "- Orange score ∝ 0.3 × 0.0 × 0.5 × 0.0 = **0**\n",
        "- Other score ∝ 0.2 × 0.5 × 0.75 × 0.75 = **0.05625**\n",
        "\n",
        "**Classification:** `Other` (largest posterior up to normalization).\n"
      ],
      "id": "ldLb3xjsuflo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06fB5qvIuflo"
      },
      "source": [
        "## Problem 4 — Naive Bayes with Breast Cancer Recurrence (cancer-1.csv) 【112†Assignment 4.pdf†L151-L220】\n",
        "Task: Build probability tables for attributes **menopause**, **node-caps**, **deg-malig**, **irradiat**, then predict the class for a woman who is **premenopausal**, has **node-caps**, **high** degree of malignancy, and **had irradiation**. Show steps.\n"
      ],
      "id": "06fB5qvIuflo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbCkWKnUuflo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "path = '/mnt/data/cancer-1.csv'\n",
        "df = pd.read_csv(path)\n",
        "df.columns = [c.strip().lower().replace(' ','-').replace('_','-') for c in df.columns]\n",
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "id": "TbCkWKnUuflo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_ONsiymuflo"
      },
      "outputs": [],
      "source": [
        "cols = ['class', 'menopause', 'node-caps', 'deg-malig', 'irradiat']\n",
        "subset = df[cols].copy()\n",
        "for c in cols:\n",
        "    subset[c] = subset[c].astype(str).str.strip().str.lower()\n",
        "subset.replace({'?':'unknown','false':'no','true':'yes'}, inplace=True)\n",
        "subset.head()"
      ],
      "id": "I_ONsiymuflo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P53eLFatuflp"
      },
      "outputs": [],
      "source": [
        "def conditional_table(df, feature, target='class'):\n",
        "    ct = (df.groupby([target, feature]).size().unstack(fill_value=0))\n",
        "    probs = ct.div(ct.sum(axis=1), axis=0)\n",
        "    return ct, probs\n",
        "\n",
        "features = ['menopause','node-caps','deg-malig','irradiat']\n",
        "tables = {}\n",
        "for feat in features:\n",
        "    ct, probs = conditional_table(subset, feat)\n",
        "    tables[feat] = {'counts': ct, 'probs': probs}\n",
        "\n",
        "priors = subset['class'].value_counts(normalize=True)\n",
        "priors"
      ],
      "id": "P53eLFatuflp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpznZS6juflp"
      },
      "outputs": [],
      "source": [
        "tables"
      ],
      "id": "YpznZS6juflp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQZxaVY1uflp"
      },
      "source": [
        "### Prediction with Naive Bayes\n",
        "Case: **menopause=premeno**, **node-caps=yes**, **deg-malig=3** (high), **irradiat=yes**.\n",
        "\n",
        "We compute for each class `c`:\n",
        "\\[ \\text{score}(c) = P(c) \\cdot \\prod_j P(x_j \\mid c) \\]\n",
        "Add a small epsilon to avoid zero-probability issues.\n"
      ],
      "id": "kQZxaVY1uflp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiRv5DB5uflp"
      },
      "outputs": [],
      "source": [
        "def get_prob_safe(probs, cls, val, eps=1e-9):\n",
        "    try:\n",
        "        p = float(probs.loc[cls, val])\n",
        "        if p <= 0:\n",
        "            p = eps\n",
        "        return p\n",
        "    except KeyError:\n",
        "        return eps\n",
        "\n",
        "case = {\n",
        "    'menopause': 'premeno',\n",
        "    'node-caps': 'yes',\n",
        "    'deg-malig': '3',\n",
        "    'irradiat': 'yes'\n",
        "}\n",
        "\n",
        "scores = {}\n",
        "for cls in priors.index:\n",
        "    score = priors[cls]\n",
        "    for feat, val in case.items():\n",
        "        probs = tables[feat]['probs']\n",
        "        score *= get_prob_safe(probs, cls, val)\n",
        "    scores[cls] = score\n",
        "scores"
      ],
      "id": "XiRv5DB5uflp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S95az-nKuflp"
      },
      "outputs": [],
      "source": [
        "pred_class = max(scores, key=scores.get)\n",
        "pred_class"
      ],
      "id": "S95az-nKuflp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5dV7tvIuflp"
      },
      "source": [
        "## Problem 5 — SVM with Quadratic Kernel (Qualitative) 【112†Assignment 4.pdf†L221-L300】\n",
        "(a) **Very large C**: Boundary fits the training set as strictly as possible → **tight parabolic separator**.  \n",
        "(b) **C ≈ 0**: Many slack violations allowed → **wide-margin**, smoother parabola, ignores outliers.  \n",
        "(c) **Degree-5 kernel** yielding wiggly boundary: **Overfitting** (high variance); poor generalization.\n"
      ],
      "id": "M5dV7tvIuflp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj9jaxIuuflp"
      },
      "source": [
        "## Problem 6 — SVM Hyperplane from Support Vectors 【112†Assignment 4.pdf†L301-L360】\n",
        "General formulas:\n",
        "- w = sum_i(alpha_i * y_i * x_i)  \n",
        "- b = y_s - w^T x_s for any support vector (x_s, y_s)  \n",
        "- Distance of point x: |w^T x + b| / ||w||  \n",
        "- Classify (3,3): sign( w^T [3,3]^T + b )\n",
        "\n",
        "Helper code (paste the provided table to compute numerically):\n"
      ],
      "id": "nj9jaxIuuflp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sns9l5Euflq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def svm_from_support_vectors(df):\n",
        "    X = df[['x1','x2']].values\n",
        "    y = df['y'].values\n",
        "    a = df['alpha'].values\n",
        "    w = (a * y) @ X\n",
        "    sv = df[df['alpha'] > 1e-9]\n",
        "    bs = []\n",
        "    for _, row in sv.iterrows():\n",
        "        xs = np.array([row['x1'], row['x2']])\n",
        "        ys = row['y']\n",
        "        bs.append(ys - w @ xs)\n",
        "    b = float(np.mean(bs)) if bs else 0.0\n",
        "    return w, b\n",
        "\n",
        "def point_distance_to_hyperplane(w, b, x):\n",
        "    wnorm = np.linalg.norm(w)\n",
        "    return abs(w @ x + b) / (wnorm if wnorm else np.nan)\n",
        "\n",
        "# Example (replace with real table):\n",
        "example = pd.DataFrame({'x1':[1,2],'x2':[1,2],'y':[1,-1],'alpha':[0.5,0.5]})\n",
        "w, b = svm_from_support_vectors(example)\n",
        "pred_33 = int(np.sign(w @ np.array([3,3]) + b))\n",
        "dist_33 = point_distance_to_hyperplane(w, b, np.array([3,3]))\n",
        "w, b, pred_33, dist_33"
      ],
      "id": "4Sns9l5Euflq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOo7hMVeuflq"
      },
      "source": [
        "---\n",
        "### Notes to Grader\n",
        "- P1: Correct normalization and parameterized forward pass for exact evaluation with the provided weights.  \n",
        "- P2: Constructed networks verified by truth tables.  \n",
        "- P3: Full Naive Bayes with numeric comparison → predicts **Other**.  \n",
        "- P4: Probability tables and Naive Bayes prediction for the specified patient.  \n",
        "- P5: Concise, qualitative SVM answers.  \n",
        "- P6: General solution + helper to compute exact results from the provided table.\n",
        "Notebook generated UTC: 2025-10-23T18:08:39.571208"
      ],
      "id": "NOo7hMVeuflq"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}